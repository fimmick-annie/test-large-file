{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Model"
      ],
      "metadata": {
        "id": "8dskNorye4RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SFT_llama2ch_Alpaca"
      ],
      "metadata": {
        "id": "UuNYlhfvzAI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Llama2_ch/')"
      ],
      "metadata": {
        "id": "Ak49HSbQ1Q5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ymcui/Chinese-LLaMA-Alpaca-2.git\n",
        "!pip install -r requirements.txt\n",
        "!pip install datasets\n",
        "!pip install deepspeed\n",
        "!pip install einops\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuQgZ9gOy-9Q",
        "outputId": "52586aa5-04c0-49e6-8d06-037c89e67f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft>=0.3.0 (from -r Chinese-LLaMA-Alpaca-2/requirements.txt (line 1))\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/85.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (2.0.1+cu118)\n",
            "Collecting transformers==4.31.0 (from -r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.97 (from -r Chinese-LLaMA-Alpaca-2/requirements.txt (line 4))\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.41.0 (from -r Chinese-LLaMA-Alpaca-2/requirements.txt (line 5))\n",
            "  Downloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (2.0.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3))\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (16.0.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft>=0.3.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 1)) (5.9.5)\n",
            "Collecting accelerate (from peft>=0.3.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 1))\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 3)) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r Chinese-LLaMA-Alpaca-2/requirements.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, bitsandbytes, huggingface-hub, transformers, accelerate, peft\n",
            "Successfully installed accelerate-0.23.0 bitsandbytes-0.41.0 huggingface-hub-0.17.2 peft-0.5.0 safetensors-0.3.3 sentencepiece-0.1.97 tokenizers-0.13.3 transformers-4.31.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.10.3.tar.gz (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.3/867.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.10.3-py3-none-any.whl size=907838 sha256=3bf10079bf6f09e4b36f939abb1519a9335cfcf9d77d6be5e82eea41cd5f346e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/8e/fe/bd6467e058672bf39888e67b763f706053f6f969fe0542423d\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: ninja, hjson, deepspeed\n",
            "Successfully installed deepspeed-0.10.3 hjson-3.1.0 ninja-1.11.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.2.5.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.0.1+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.2.5-cp310-cp310-linux_x86_64.whl size=37144723 sha256=29ece06e8598723c1a7e61493c3d0850820a4679de8b25ccbb0700c7bda82edc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/9c/e5/f76917b893fe20f6a453055d214aa4e58f286f6b9f5f977a2c\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Llama2_ch/scripts/training')"
      ],
      "metadata": {
        "id": "NoFLWVlgYIEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run_sft.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzFGw2tI1yb6",
        "outputId": "58244ed7-9357-4504-d676-1e1631b9b6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-25 02:07:22.410061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-09-25 02:07:33,473] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-09-25 02:07:37,979] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2023-09-25 02:07:37,980] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "09/25/2023 02:07:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
            "[INFO|configuration_utils.py:710] 2023-09-25 02:07:40,583 >> loading configuration file /content/drive/MyDrive/Llama2_ch/models/config.json\n",
            "[INFO|configuration_utils.py:768] 2023-09-25 02:07:40,584 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Llama2_ch/models\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 5120,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 13824,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 40,\n",
            "  \"num_hidden_layers\": 40,\n",
            "  \"num_key_value_heads\": 40,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 55296\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1837] 2023-09-25 02:07:40,586 >> loading file tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:1837] 2023-09-25 02:07:40,586 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1837] 2023-09-25 02:07:40,586 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1837] 2023-09-25 02:07:40,586 >> loading file tokenizer_config.json\n",
            "[WARNING|logging.py:295] 2023-09-25 02:07:41,180 >> You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "09/25/2023 02:07:45 - INFO - __main__ - Training files: /content/drive/MyDrive/Llama2_ch/data/train/train.json\n",
            "09/25/2023 02:07:45 - WARNING - root - building dataset...\n",
            "Using custom data configuration default-f49c3fd2fbfd5a64\n",
            "09/25/2023 02:07:46 - INFO - datasets.builder - Using custom data configuration default-f49c3fd2fbfd5a64\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "09/25/2023 02:07:46 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "Generating dataset json (/content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "09/25/2023 02:07:46 - INFO - datasets.builder - Generating dataset json (/content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "Downloading and preparing dataset json/default to /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "09/25/2023 02:07:46 - INFO - datasets.builder - Downloading and preparing dataset json/default to /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 1954.48it/s]\n",
            "Downloading took 0.0 min\n",
            "09/25/2023 02:07:46 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "09/25/2023 02:07:46 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 1/1 [00:02<00:00,  2.87s/it]\n",
            "Generating train split\n",
            "09/25/2023 02:07:49 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 378 examples [00:00, 676.07 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "09/25/2023 02:07:50 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "09/25/2023 02:07:50 - INFO - datasets.builder - Dataset json downloaded and prepared to /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "Process #0 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00000_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #0 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00000_of_00008.arrow\n",
            "Process #1 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00001_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #1 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00001_of_00008.arrow\n",
            "Process #2 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00002_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #2 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00002_of_00008.arrow\n",
            "Process #3 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00003_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #3 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00003_of_00008.arrow\n",
            "Process #4 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00004_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #4 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00004_of_00008.arrow\n",
            "Process #5 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00005_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #5 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00005_of_00008.arrow\n",
            "Process #6 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00006_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #6 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00006_of_00008.arrow\n",
            "Process #7 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00007_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Process #7 will write at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00007_of_00008.arrow\n",
            "Spawning 8 processes\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Spawning 8 processes\n",
            "preprocessing on dataset (num_proc=8):   0% 0/378 [00:00<?, ? examples/s]Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00000_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00000_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00004_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00006_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00004_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00006_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00002_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00001_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00002_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00001_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00003_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00003_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00007_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00007_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00005_of_00008.arrow\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/train/train_512/json/default-f49c3fd2fbfd5a64/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-52e779d787763209_00005_of_00008.arrow\n",
            "preprocessing on dataset (num_proc=8): 100% 378/378 [00:00<00:00, 943.17 examples/s]\n",
            "Concatenating 8 shards\n",
            "09/25/2023 02:07:50 - INFO - datasets.arrow_dataset - Concatenating 8 shards\n",
            "Saving the dataset (1/1 shards): 100% 378/378 [00:00<00:00, 12429.13 examples/s]\n",
            "09/25/2023 02:07:51 - INFO - __main__ - Num train_samples  378\n",
            "09/25/2023 02:07:51 - INFO - __main__ - Training example:\n",
            "09/25/2023 02:07:51 - INFO - __main__ - <s> [INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "使用者:使用者想找美食，請在接下來的對話中，問使用者[]內的5個問題，不重複問且隨機抽取[]內的問題，每輪對話只問一個問題，一直到[]內的5個問題都問完:[1.美食地區, 2.人數, 3.用餐預算, 4.用餐時段, 5.用餐口味喜好] 助手:[/INST]好的，讓我們開始找美食吧！關於用餐的時間，您想選擇在哪個時段用餐呢？</s><s> [INST]使用者:下午茶 助手:[/INST]請問您有什麼口味喜好或特殊飲食要求嗎？例如，辣的或是不吃香菜，西式或是中式。</s><s> [INST]使用者:中式 助手:[/INST]請問您的用餐預算是多少呢？您可以提供一個大約的金額範圍或具體數字。請記得跟我說您所使用的貨幣，例如：人民幣、新台幣、港幣。</s><s> [INST]使用者:2977到7041人民幣 助手:[/INST]想請教您對於美食的地點有特別偏好嗎？</s><s> [INST]使用者:永和區 助手:[/INST]請問人數是多少？</s><s> [INST]使用者:10人 助手: [/INST] 現在我們已經瞭解您的飲食喜好，有了這些信息，我們可以開始搜尋符合您口味的美食了。</s>\n",
            "09/25/2023 02:07:51 - INFO - __main__ - Evaluation files: /content/drive/MyDrive/Llama2_ch/data/dev/dev.json\n",
            "09/25/2023 02:07:51 - WARNING - root - building dataset...\n",
            "Using custom data configuration default-8e32fbee77afb7c1\n",
            "09/25/2023 02:07:52 - INFO - datasets.builder - Using custom data configuration default-8e32fbee77afb7c1\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "09/25/2023 02:07:52 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "Generating dataset json (/content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "09/25/2023 02:07:52 - INFO - datasets.builder - Generating dataset json (/content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "Downloading and preparing dataset json/default to /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "09/25/2023 02:07:52 - INFO - datasets.builder - Downloading and preparing dataset json/default to /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 2716.52it/s]\n",
            "Downloading took 0.0 min\n",
            "09/25/2023 02:07:52 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "09/25/2023 02:07:52 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "Generating train split\n",
            "09/25/2023 02:07:55 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 512 examples [00:01, 503.97 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "09/25/2023 02:07:56 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "09/25/2023 02:07:56 - INFO - datasets.builder - Dataset json downloaded and prepared to /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "Process #0 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00000_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #0 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00000_of_00008.arrow\n",
            "Process #1 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00001_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #1 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00001_of_00008.arrow\n",
            "Process #2 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00002_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #2 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00002_of_00008.arrow\n",
            "Process #3 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00003_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #3 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00003_of_00008.arrow\n",
            "Process #4 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00004_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #4 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00004_of_00008.arrow\n",
            "Process #5 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00005_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #5 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00005_of_00008.arrow\n",
            "Process #6 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00006_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #6 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00006_of_00008.arrow\n",
            "Process #7 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00007_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Process #7 will write at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00007_of_00008.arrow\n",
            "Spawning 8 processes\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Spawning 8 processes\n",
            "preprocessing on dataset (num_proc=8):   0% 0/512 [00:00<?, ? examples/s]Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00001_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00001_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00002_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00002_of_00008.arrow\n",
            "preprocessing on dataset (num_proc=8):  12% 64/512 [00:00<00:01, 361.55 examples/s]Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00000_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00000_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00006_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00006_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00007_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00007_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00003_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00003_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00005_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00005_of_00008.arrow\n",
            "Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00004_of_00008.arrow\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/drive/MyDrive/Llama2_ch/data/dev/dev_512/json/default-8e32fbee77afb7c1/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f15d20f970fa68ce_00004_of_00008.arrow\n",
            "preprocessing on dataset (num_proc=8): 100% 512/512 [00:00<00:00, 1362.62 examples/s]\n",
            "Concatenating 8 shards\n",
            "09/25/2023 02:07:56 - INFO - datasets.arrow_dataset - Concatenating 8 shards\n",
            "Saving the dataset (1/1 shards): 100% 512/512 [00:00<00:00, 40012.74 examples/s]\n",
            "09/25/2023 02:07:56 - INFO - __main__ - Num eval_samples  512\n",
            "09/25/2023 02:07:56 - INFO - __main__ - Evaluation example:\n",
            "09/25/2023 02:07:56 - INFO - __main__ - <s> [INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "使用者:使用者想找美食，請在接下來的對話中，問使用者[]內的5個問題，不重複問且隨機抽取[]內的問題，每輪對話只問一個問題，一直到[]內的5個問題都問完:[1.美食地區, 2.人數, 3.用餐預算, 4.用餐時段, 5.用餐口味喜好] 助手:[/INST]好的，讓我們開始找美食吧！請問您有什麼口味喜好或特殊飲食要求嗎？例如，辣的或是不吃香菜，西式或是中式。</s><s> [INST]使用者:中式 助手:[/INST]關於用餐的時間，您想選擇在哪個時段用餐呢？</s><s> [INST]使用者:晚餐 助手:[/INST]請問您的用餐預算是多少呢？您可以提供一個大約的金額範圍或具體數字。請記得跟我說您所使用的貨幣，例如：人民幣、新台幣、港幣。</s><s> [INST]使用者:1826人民幣 助手:[/INST]請問人數是多少？</s><s> [INST]使用者:5人 助手: [/INST] 想請教您對於美食的地點有特別偏好嗎？</s>\n",
            "[INFO|modeling_utils.py:2600] 2023-09-25 02:07:56,679 >> loading weights file /content/drive/MyDrive/Llama2_ch/models/pytorch_model.bin.index.json\n",
            "[INFO|modeling_utils.py:1172] 2023-09-25 02:07:57,276 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:599] 2023-09-25 02:07:57,277 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.31.0\"\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 3/3 [07:46<00:00, 155.35s/it]\n",
            "[INFO|modeling_utils.py:3329] 2023-09-25 02:15:43,682 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:3337] 2023-09-25 02:15:43,682 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /content/drive/MyDrive/Llama2_ch/models.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:559] 2023-09-25 02:15:44,261 >> loading configuration file /content/drive/MyDrive/Llama2_ch/models/generation_config.json\n",
            "[INFO|configuration_utils.py:599] 2023-09-25 02:15:44,262 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 4096,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"temperature\": 0.9,\n",
            "  \"top_p\": 0.6,\n",
            "  \"transformers_version\": \"4.31.0\"\n",
            "}\n",
            "\n",
            "09/25/2023 02:15:44 - INFO - __main__ - Model vocab size: 55296\n",
            "09/25/2023 02:15:44 - INFO - __main__ - len(tokenizer):55296\n",
            "09/25/2023 02:15:44 - INFO - __main__ - Init new peft model\n",
            "09/25/2023 02:15:44 - INFO - __main__ - target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
            "09/25/2023 02:15:44 - INFO - __main__ - lora_rank: 64\n",
            "trainable params: 250347520 || all params: 13504762880 || trainable%: 1.8537720523087038\n",
            "09/25/2023 02:18:46 - INFO - __main__ - model.modules_to_save: None\n",
            "[INFO|trainer.py:386] 2023-09-25 02:18:46,306 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[2023-09-25 02:18:46,568] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown\n",
            "09/25/2023 02:18:46 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "09/25/2023 02:18:46 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "[2023-09-25 02:18:46,716] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2023-09-25 02:18:46,720] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
            "[2023-09-25 02:18:46,720] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2023-09-25 02:18:46,795] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
            "[2023-09-25 02:18:46,795] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>\n",
            "[2023-09-25 02:18:46,795] [WARNING] [engine.py:1149:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n",
            "[2023-09-25 02:18:46,795] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
            "[2023-09-25 02:18:46,795] [INFO] [stage_1_and_2.py:146:__init__] Reduce bucket size 100000000\n",
            "[2023-09-25 02:18:46,795] [INFO] [stage_1_and_2.py:147:__init__] Allgather bucket size 100000000\n",
            "[2023-09-25 02:18:46,795] [INFO] [stage_1_and_2.py:148:__init__] CPU Offload: False\n",
            "[2023-09-25 02:18:46,795] [INFO] [stage_1_and_2.py:149:__init__] Round robin gradient partitioning: False\n",
            "Rank: 0 partition count [1] and sizes[(250347520, False)] \n",
            "[2023-09-25 02:18:47,441] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states\n",
            "[2023-09-25 02:18:47,442] [INFO] [utils.py:804:see_memory_usage] MA 26.28 GB         Max_MA 26.75 GB         CA 26.75 GB         Max_CA 27 GB \n",
            "[2023-09-25 02:18:47,442] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 5.42 GB, percent = 6.5%\n",
            "[2023-09-25 02:18:47,690] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states\n",
            "[2023-09-25 02:18:47,690] [INFO] [utils.py:804:see_memory_usage] MA 28.15 GB         Max_MA 30.02 GB         CA 30.49 GB         Max_CA 30 GB \n",
            "[2023-09-25 02:18:47,691] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 5.42 GB, percent = 6.5%\n",
            "[2023-09-25 02:18:47,691] [INFO] [stage_1_and_2.py:520:__init__] optimizer state initialized\n",
            "[2023-09-25 02:18:47,898] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2023-09-25 02:18:47,899] [INFO] [utils.py:804:see_memory_usage] MA 28.15 GB         Max_MA 28.15 GB         CA 30.49 GB         Max_CA 30 GB \n",
            "[2023-09-25 02:18:47,899] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 5.42 GB, percent = 6.5%\n",
            "[2023-09-25 02:18:47,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW\n",
            "[2023-09-25 02:18:47,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2023-09-25 02:18:47,918] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2023-09-25 02:18:47,918] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
            "[2023-09-25 02:18:47,921] [INFO] [config.py:967:print] DeepSpeedEngine configuration:\n",
            "[2023-09-25 02:18:47,921] [INFO] [config.py:971:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-09-25 02:18:47,921] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-09-25 02:18:47,921] [INFO] [config.py:971:print]   amp_enabled .................. False\n",
            "[2023-09-25 02:18:47,921] [INFO] [config.py:971:print]   amp_params ................... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   bfloat16_enabled ............. False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7db57f1dffd0>\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   communication_data_type ...... None\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   dataloader_drop_last ......... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   disable_allgather ............ False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   dump_state ................... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1e-10}\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   elasticity_enabled ........... False\n",
            "[2023-09-25 02:18:47,922] [INFO] [config.py:971:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   fp16_auto_cast ............... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   fp16_enabled ................. True\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   global_rank .................. 0\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   grad_accum_dtype ............. None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 8\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   load_universal_checkpoint .... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   loss_scale ................... 0\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   memory_breakdown ............. False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   mics_shard_size .............. -1\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   optimizer_name ............... None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   optimizer_params ............. None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   pld_enabled .................. False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   pld_params ................... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   prescale_gradients ........... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   scheduler_name ............... None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   scheduler_params ............. None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   sparse_attention ............. None\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   steps_per_print .............. inf\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   train_batch_size ............. 8\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   use_node_local_storage ....... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False\n",
            "[2023-09-25 02:18:47,923] [INFO] [config.py:971:print]   weight_quantization_config ... None\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   world_size ................... 1\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  True\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=100000000 allgather_partitions=True allgather_bucket_size=100000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   zero_enabled ................. True\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:971:print]   zero_optimization_stage ...... 2\n",
            "[2023-09-25 02:18:47,924] [INFO] [config.py:957:print_user_config]   json = {\n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 100, \n",
            "        \"initial_scale_power\": 16, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1e-10\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 1.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 1.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"gradient_accumulation_steps\": 8, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"steps_per_print\": inf, \n",
            "    \"train_batch_size\": 8, \n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"bf16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"zero_allow_untested_optimizer\": true\n",
            "}\n",
            "[INFO|trainer.py:1686] 2023-09-25 02:18:47,924 >> ***** Running training *****\n",
            "[INFO|trainer.py:1687] 2023-09-25 02:18:47,924 >>   Num examples = 378\n",
            "[INFO|trainer.py:1688] 2023-09-25 02:18:47,924 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:1689] 2023-09-25 02:18:47,924 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1692] 2023-09-25 02:18:47,924 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1693] 2023-09-25 02:18:47,924 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:1694] 2023-09-25 02:18:47,924 >>   Total optimization steps = 235\n",
            "[INFO|trainer.py:1695] 2023-09-25 02:18:47,928 >>   Number of trainable parameters = 250,347,520\n",
            "{'loss': 2.7562, 'learning_rate': 1.25e-05, 'epoch': 0.02}\n",
            "{'loss': 1.5327, 'learning_rate': 9.998084772789603e-05, 'epoch': 0.21}\n",
            "{'loss': 0.203, 'learning_rate': 9.931205754581203e-05, 'epoch': 0.42}\n",
            "{'loss': 0.099, 'learning_rate': 9.770027569437253e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0458, 'learning_rate': 9.517632418617173e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0504, 'learning_rate': 9.178846840222488e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0474, 'learning_rate': 8.760149411583437e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0502, 'learning_rate': 8.269546859793497e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0378, 'learning_rate': 7.71642094952296e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0286, 'learning_rate': 7.111349076067187e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0492, 'learning_rate': 6.465901994418505e-05, 'epoch': 2.12}\n",
            " 43% 100/235 [06:07<08:13,  3.65s/it][INFO|trainer.py:3081] 2023-09-25 02:24:55,992 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3083] 2023-09-25 02:24:55,992 >>   Num examples = 512\n",
            "[INFO|trainer.py:3086] 2023-09-25 02:24:55,992 >>   Batch size = 1\n",
            "\n",
            "  0% 0/512 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/512 [00:00<00:26, 19.43it/s]\u001b[A\n",
            "  1% 4/512 [00:00<00:41, 12.38it/s]\u001b[A\n",
            "  1% 6/512 [00:00<00:46, 10.90it/s]\u001b[A\n",
            "  2% 8/512 [00:00<00:48, 10.34it/s]\u001b[A\n",
            "  2% 10/512 [00:00<00:49, 10.07it/s]\u001b[A\n",
            "  2% 12/512 [00:01<00:50,  9.93it/s]\u001b[A\n",
            "  3% 14/512 [00:01<00:50,  9.87it/s]\u001b[A\n",
            "  3% 16/512 [00:01<00:50,  9.92it/s]\u001b[A\n",
            "  4% 18/512 [00:01<00:50,  9.83it/s]\u001b[A\n",
            "  4% 19/512 [00:01<00:50,  9.83it/s]\u001b[A\n",
            "  4% 20/512 [00:01<00:49,  9.86it/s]\u001b[A\n",
            "  4% 21/512 [00:02<00:49,  9.83it/s]\u001b[A\n",
            "  4% 22/512 [00:02<00:50,  9.77it/s]\u001b[A\n",
            "  4% 23/512 [00:02<00:49,  9.78it/s]\u001b[A\n",
            "  5% 24/512 [00:02<00:50,  9.73it/s]\u001b[A\n",
            "  5% 25/512 [00:02<00:50,  9.70it/s]\u001b[A\n",
            "  5% 26/512 [00:02<00:49,  9.75it/s]\u001b[A\n",
            "  5% 28/512 [00:02<00:49,  9.83it/s]\u001b[A\n",
            "  6% 29/512 [00:02<00:49,  9.76it/s]\u001b[A\n",
            "  6% 31/512 [00:03<00:48,  9.82it/s]\u001b[A\n",
            "  6% 32/512 [00:03<00:49,  9.76it/s]\u001b[A\n",
            "  7% 34/512 [00:03<00:48,  9.80it/s]\u001b[A\n",
            "  7% 36/512 [00:03<00:48,  9.86it/s]\u001b[A\n",
            "  7% 38/512 [00:03<00:47,  9.98it/s]\u001b[A\n",
            "  8% 40/512 [00:03<00:47,  9.94it/s]\u001b[A\n",
            "  8% 41/512 [00:04<00:47,  9.88it/s]\u001b[A\n",
            "  8% 43/512 [00:04<00:47,  9.89it/s]\u001b[A\n",
            "  9% 44/512 [00:04<00:47,  9.89it/s]\u001b[A\n",
            "  9% 45/512 [00:04<00:47,  9.89it/s]\u001b[A\n",
            "  9% 46/512 [00:04<00:47,  9.79it/s]\u001b[A\n",
            "  9% 47/512 [00:04<00:47,  9.74it/s]\u001b[A\n",
            "  9% 48/512 [00:04<00:47,  9.75it/s]\u001b[A\n",
            " 10% 49/512 [00:04<00:47,  9.76it/s]\u001b[A\n",
            " 10% 50/512 [00:05<00:47,  9.76it/s]\u001b[A\n",
            " 10% 52/512 [00:05<00:46,  9.83it/s]\u001b[A\n",
            " 10% 53/512 [00:05<00:46,  9.84it/s]\u001b[A\n",
            " 11% 54/512 [00:05<00:46,  9.86it/s]\u001b[A\n",
            " 11% 55/512 [00:05<00:46,  9.74it/s]\u001b[A\n",
            " 11% 57/512 [00:05<00:46,  9.74it/s]\u001b[A\n",
            " 11% 58/512 [00:05<00:46,  9.70it/s]\u001b[A\n",
            " 12% 59/512 [00:05<00:46,  9.75it/s]\u001b[A\n",
            " 12% 60/512 [00:06<00:46,  9.71it/s]\u001b[A\n",
            " 12% 61/512 [00:06<00:46,  9.76it/s]\u001b[A\n",
            " 12% 62/512 [00:06<00:46,  9.72it/s]\u001b[A\n",
            " 12% 64/512 [00:06<00:45,  9.84it/s]\u001b[A\n",
            " 13% 65/512 [00:06<00:45,  9.82it/s]\u001b[A\n",
            " 13% 66/512 [00:06<00:45,  9.78it/s]\u001b[A\n",
            " 13% 67/512 [00:06<00:45,  9.73it/s]\u001b[A\n",
            " 13% 68/512 [00:06<00:45,  9.76it/s]\u001b[A\n",
            " 13% 69/512 [00:06<00:45,  9.73it/s]\u001b[A\n",
            " 14% 71/512 [00:07<00:44,  9.97it/s]\u001b[A\n",
            " 14% 73/512 [00:07<00:44,  9.94it/s]\u001b[A\n",
            " 14% 74/512 [00:07<00:44,  9.92it/s]\u001b[A\n",
            " 15% 75/512 [00:07<00:44,  9.84it/s]\u001b[A\n",
            " 15% 76/512 [00:07<00:44,  9.85it/s]\u001b[A\n",
            " 15% 77/512 [00:07<00:44,  9.82it/s]\u001b[A\n",
            " 15% 78/512 [00:07<00:44,  9.86it/s]\u001b[A\n",
            " 15% 79/512 [00:07<00:44,  9.78it/s]\u001b[A\n",
            " 16% 80/512 [00:08<00:44,  9.73it/s]\u001b[A\n",
            " 16% 81/512 [00:08<00:44,  9.67it/s]\u001b[A\n",
            " 16% 82/512 [00:08<00:44,  9.64it/s]\u001b[A\n",
            " 16% 83/512 [00:08<00:44,  9.71it/s]\u001b[A\n",
            " 16% 84/512 [00:08<00:44,  9.68it/s]\u001b[A\n",
            " 17% 86/512 [00:08<00:43,  9.78it/s]\u001b[A\n",
            " 17% 87/512 [00:08<00:43,  9.71it/s]\u001b[A\n",
            " 17% 88/512 [00:08<00:43,  9.74it/s]\u001b[A\n",
            " 17% 89/512 [00:08<00:43,  9.75it/s]\u001b[A\n",
            " 18% 90/512 [00:09<00:43,  9.79it/s]\u001b[A\n",
            " 18% 92/512 [00:09<00:42,  9.96it/s]\u001b[A\n",
            " 18% 93/512 [00:09<00:42,  9.88it/s]\u001b[A\n",
            " 18% 94/512 [00:09<00:42,  9.84it/s]\u001b[A\n",
            " 19% 95/512 [00:09<00:42,  9.78it/s]\u001b[A\n",
            " 19% 96/512 [00:09<00:42,  9.83it/s]\u001b[A\n",
            " 19% 97/512 [00:09<00:42,  9.82it/s]\u001b[A\n",
            " 19% 98/512 [00:09<00:42,  9.80it/s]\u001b[A\n",
            " 19% 99/512 [00:10<00:42,  9.77it/s]\u001b[A\n",
            " 20% 100/512 [00:10<00:42,  9.74it/s]\u001b[A\n",
            " 20% 101/512 [00:10<00:42,  9.70it/s]\u001b[A\n",
            " 20% 102/512 [00:10<00:42,  9.70it/s]\u001b[A\n",
            " 20% 104/512 [00:10<00:41,  9.77it/s]\u001b[A\n",
            " 21% 105/512 [00:10<00:43,  9.46it/s]\u001b[A\n",
            " 21% 106/512 [00:10<00:42,  9.50it/s]\u001b[A\n",
            " 21% 107/512 [00:10<00:42,  9.61it/s]\u001b[A\n",
            " 21% 108/512 [00:10<00:41,  9.65it/s]\u001b[A\n",
            " 21% 109/512 [00:11<00:41,  9.66it/s]\u001b[A\n",
            " 21% 110/512 [00:11<00:41,  9.70it/s]\u001b[A\n",
            " 22% 111/512 [00:11<00:41,  9.73it/s]\u001b[A\n",
            " 22% 112/512 [00:11<00:41,  9.75it/s]\u001b[A\n",
            " 22% 114/512 [00:11<00:40,  9.83it/s]\u001b[A\n",
            " 23% 116/512 [00:11<00:40,  9.87it/s]\u001b[A\n",
            " 23% 117/512 [00:11<00:40,  9.87it/s]\u001b[A\n",
            " 23% 118/512 [00:11<00:39,  9.86it/s]\u001b[A\n",
            " 23% 120/512 [00:12<00:39,  9.97it/s]\u001b[A\n",
            " 24% 122/512 [00:12<00:39,  9.97it/s]\u001b[A\n",
            " 24% 124/512 [00:12<00:38, 10.00it/s]\u001b[A\n",
            " 24% 125/512 [00:12<00:38,  9.93it/s]\u001b[A\n",
            " 25% 126/512 [00:12<00:38,  9.91it/s]\u001b[A\n",
            " 25% 128/512 [00:12<00:38,  9.91it/s]\u001b[A\n",
            " 25% 129/512 [00:13<00:38,  9.86it/s]\u001b[A\n",
            " 25% 130/512 [00:13<00:38,  9.82it/s]\u001b[A\n",
            " 26% 131/512 [00:13<00:38,  9.82it/s]\u001b[A\n",
            " 26% 132/512 [00:13<00:38,  9.80it/s]\u001b[A\n",
            " 26% 133/512 [00:13<00:38,  9.80it/s]\u001b[A\n",
            " 26% 134/512 [00:13<00:38,  9.79it/s]\u001b[A\n",
            " 27% 136/512 [00:13<00:37,  9.90it/s]\u001b[A\n",
            " 27% 137/512 [00:13<00:37,  9.87it/s]\u001b[A\n",
            " 27% 139/512 [00:14<00:37, 10.03it/s]\u001b[A\n",
            " 28% 141/512 [00:14<00:36, 10.10it/s]\u001b[A\n",
            " 28% 143/512 [00:14<00:36, 10.07it/s]\u001b[A\n",
            " 28% 145/512 [00:14<00:36,  9.98it/s]\u001b[A\n",
            " 29% 146/512 [00:14<00:36,  9.90it/s]\u001b[A\n",
            " 29% 147/512 [00:14<00:37,  9.83it/s]\u001b[A\n",
            " 29% 148/512 [00:14<00:36,  9.85it/s]\u001b[A\n",
            " 29% 149/512 [00:15<00:37,  9.78it/s]\u001b[A\n",
            " 29% 150/512 [00:15<00:37,  9.75it/s]\u001b[A\n",
            " 29% 151/512 [00:15<00:36,  9.78it/s]\u001b[A\n",
            " 30% 152/512 [00:15<00:37,  9.71it/s]\u001b[A\n",
            " 30% 153/512 [00:15<00:37,  9.69it/s]\u001b[A\n",
            " 30% 154/512 [00:15<00:37,  9.67it/s]\u001b[A\n",
            " 30% 156/512 [00:15<00:36,  9.81it/s]\u001b[A\n",
            " 31% 157/512 [00:15<00:36,  9.79it/s]\u001b[A\n",
            " 31% 158/512 [00:16<00:36,  9.78it/s]\u001b[A\n",
            " 31% 159/512 [00:16<00:36,  9.75it/s]\u001b[A\n",
            " 31% 160/512 [00:16<00:36,  9.77it/s]\u001b[A\n",
            " 31% 161/512 [00:16<00:36,  9.68it/s]\u001b[A\n",
            " 32% 162/512 [00:16<00:36,  9.71it/s]\u001b[A\n",
            " 32% 163/512 [00:16<00:35,  9.77it/s]\u001b[A\n",
            " 32% 164/512 [00:16<00:35,  9.76it/s]\u001b[A\n",
            " 32% 165/512 [00:16<00:35,  9.76it/s]\u001b[A\n",
            " 32% 166/512 [00:16<00:35,  9.77it/s]\u001b[A\n",
            " 33% 167/512 [00:16<00:35,  9.80it/s]\u001b[A\n",
            " 33% 168/512 [00:17<00:35,  9.77it/s]\u001b[A\n",
            " 33% 169/512 [00:17<00:35,  9.78it/s]\u001b[A\n",
            " 33% 170/512 [00:17<00:35,  9.77it/s]\u001b[A\n",
            " 33% 171/512 [00:17<00:34,  9.83it/s]\u001b[A\n",
            " 34% 172/512 [00:17<00:34,  9.81it/s]\u001b[A\n",
            " 34% 173/512 [00:17<00:34,  9.75it/s]\u001b[A\n",
            " 34% 174/512 [00:17<00:34,  9.72it/s]\u001b[A\n",
            " 34% 176/512 [00:17<00:34,  9.78it/s]\u001b[A\n",
            " 35% 177/512 [00:17<00:34,  9.76it/s]\u001b[A\n",
            " 35% 179/512 [00:18<00:33,  9.83it/s]\u001b[A\n",
            " 35% 180/512 [00:18<00:33,  9.80it/s]\u001b[A\n",
            " 35% 181/512 [00:18<00:33,  9.75it/s]\u001b[A\n",
            " 36% 182/512 [00:18<00:33,  9.75it/s]\u001b[A\n",
            " 36% 183/512 [00:18<00:33,  9.71it/s]\u001b[A\n",
            " 36% 185/512 [00:18<00:33,  9.84it/s]\u001b[A\n",
            " 36% 186/512 [00:18<00:33,  9.71it/s]\u001b[A\n",
            " 37% 187/512 [00:18<00:33,  9.76it/s]\u001b[A\n",
            " 37% 188/512 [00:19<00:33,  9.71it/s]\u001b[A\n",
            " 37% 189/512 [00:19<00:33,  9.66it/s]\u001b[A\n",
            " 37% 190/512 [00:19<00:33,  9.66it/s]\u001b[A\n",
            " 37% 191/512 [00:19<00:33,  9.73it/s]\u001b[A\n",
            " 38% 192/512 [00:19<00:33,  9.67it/s]\u001b[A\n",
            " 38% 193/512 [00:19<00:32,  9.68it/s]\u001b[A\n",
            " 38% 194/512 [00:19<00:32,  9.74it/s]\u001b[A\n",
            " 38% 195/512 [00:19<00:32,  9.71it/s]\u001b[A\n",
            " 38% 196/512 [00:19<00:32,  9.70it/s]\u001b[A\n",
            " 38% 197/512 [00:20<00:32,  9.68it/s]\u001b[A\n",
            " 39% 198/512 [00:20<00:32,  9.69it/s]\u001b[A\n",
            " 39% 199/512 [00:20<00:32,  9.64it/s]\u001b[A\n",
            " 39% 200/512 [00:20<00:32,  9.71it/s]\u001b[A\n",
            " 39% 201/512 [00:20<00:32,  9.69it/s]\u001b[A\n",
            " 39% 202/512 [00:20<00:31,  9.70it/s]\u001b[A\n",
            " 40% 203/512 [00:20<00:32,  9.64it/s]\u001b[A\n",
            " 40% 204/512 [00:20<00:31,  9.63it/s]\u001b[A\n",
            " 40% 205/512 [00:20<00:31,  9.61it/s]\u001b[A\n",
            " 40% 206/512 [00:20<00:31,  9.60it/s]\u001b[A\n",
            " 40% 207/512 [00:21<00:31,  9.64it/s]\u001b[A\n",
            " 41% 208/512 [00:21<00:31,  9.70it/s]\u001b[A\n",
            " 41% 209/512 [00:21<00:31,  9.67it/s]\u001b[A\n",
            " 41% 210/512 [00:21<00:31,  9.60it/s]\u001b[A\n",
            " 41% 212/512 [00:21<00:30,  9.70it/s]\u001b[A\n",
            " 42% 214/512 [00:21<00:30,  9.84it/s]\u001b[A\n",
            " 42% 216/512 [00:21<00:29,  9.88it/s]\u001b[A\n",
            " 42% 217/512 [00:22<00:30,  9.81it/s]\u001b[A\n",
            " 43% 218/512 [00:22<00:29,  9.83it/s]\u001b[A\n",
            " 43% 220/512 [00:22<00:29,  9.86it/s]\u001b[A\n",
            " 43% 221/512 [00:22<00:29,  9.81it/s]\u001b[A\n",
            " 43% 222/512 [00:22<00:29,  9.80it/s]\u001b[A\n",
            " 44% 224/512 [00:22<00:29,  9.92it/s]\u001b[A\n",
            " 44% 225/512 [00:22<00:29,  9.87it/s]\u001b[A\n",
            " 44% 226/512 [00:22<00:28,  9.87it/s]\u001b[A\n",
            " 44% 227/512 [00:23<00:28,  9.84it/s]\u001b[A\n",
            " 45% 228/512 [00:23<00:29,  9.78it/s]\u001b[A\n",
            " 45% 229/512 [00:23<00:29,  9.74it/s]\u001b[A\n",
            " 45% 231/512 [00:23<00:28,  9.88it/s]\u001b[A\n",
            " 45% 232/512 [00:23<00:28,  9.86it/s]\u001b[A\n",
            " 46% 233/512 [00:23<00:28,  9.80it/s]\u001b[A\n",
            " 46% 234/512 [00:23<00:28,  9.78it/s]\u001b[A\n",
            " 46% 235/512 [00:23<00:28,  9.74it/s]\u001b[A\n",
            " 46% 236/512 [00:24<00:28,  9.70it/s]\u001b[A\n",
            " 46% 237/512 [00:24<00:28,  9.66it/s]\u001b[A\n",
            " 46% 238/512 [00:24<00:28,  9.72it/s]\u001b[A\n",
            " 47% 239/512 [00:24<00:28,  9.74it/s]\u001b[A\n",
            " 47% 240/512 [00:24<00:28,  9.71it/s]\u001b[A\n",
            " 47% 241/512 [00:24<00:27,  9.68it/s]\u001b[A\n",
            " 47% 242/512 [00:24<00:27,  9.69it/s]\u001b[A\n",
            " 47% 243/512 [00:24<00:27,  9.65it/s]\u001b[A\n",
            " 48% 244/512 [00:24<00:27,  9.65it/s]\u001b[A\n",
            " 48% 245/512 [00:24<00:27,  9.60it/s]\u001b[A\n",
            " 48% 246/512 [00:25<00:27,  9.64it/s]\u001b[A\n",
            " 48% 247/512 [00:25<00:27,  9.61it/s]\u001b[A\n",
            " 48% 248/512 [00:25<00:27,  9.63it/s]\u001b[A\n",
            " 49% 249/512 [00:25<00:27,  9.65it/s]\u001b[A\n",
            " 49% 250/512 [00:25<00:26,  9.73it/s]\u001b[A\n",
            " 49% 251/512 [00:25<00:26,  9.76it/s]\u001b[A\n",
            " 49% 252/512 [00:25<00:26,  9.76it/s]\u001b[A\n",
            " 49% 253/512 [00:25<00:26,  9.71it/s]\u001b[A\n",
            " 50% 254/512 [00:25<00:26,  9.71it/s]\u001b[A\n",
            " 50% 255/512 [00:25<00:26,  9.73it/s]\u001b[A\n",
            " 50% 256/512 [00:26<00:26,  9.68it/s]\u001b[A\n",
            " 50% 257/512 [00:26<00:26,  9.60it/s]\u001b[A\n",
            " 50% 258/512 [00:26<00:26,  9.67it/s]\u001b[A\n",
            " 51% 259/512 [00:26<00:26,  9.67it/s]\u001b[A\n",
            " 51% 260/512 [00:26<00:25,  9.70it/s]\u001b[A\n",
            " 51% 261/512 [00:26<00:25,  9.70it/s]\u001b[A\n",
            " 51% 262/512 [00:26<00:25,  9.71it/s]\u001b[A\n",
            " 51% 263/512 [00:26<00:25,  9.71it/s]\u001b[A\n",
            " 52% 264/512 [00:26<00:25,  9.72it/s]\u001b[A\n",
            " 52% 265/512 [00:27<00:25,  9.72it/s]\u001b[A\n",
            " 52% 266/512 [00:27<00:25,  9.62it/s]\u001b[A\n",
            " 52% 267/512 [00:27<00:25,  9.68it/s]\u001b[A\n",
            " 52% 268/512 [00:27<00:25,  9.70it/s]\u001b[A\n",
            " 53% 270/512 [00:27<00:24,  9.79it/s]\u001b[A\n",
            " 53% 271/512 [00:27<00:24,  9.76it/s]\u001b[A\n",
            " 53% 273/512 [00:27<00:24,  9.80it/s]\u001b[A\n",
            " 54% 274/512 [00:27<00:24,  9.80it/s]\u001b[A\n",
            " 54% 275/512 [00:28<00:24,  9.79it/s]\u001b[A\n",
            " 54% 276/512 [00:28<00:24,  9.75it/s]\u001b[A\n",
            " 54% 277/512 [00:28<00:24,  9.76it/s]\u001b[A\n",
            " 54% 278/512 [00:28<00:24,  9.72it/s]\u001b[A\n",
            " 54% 279/512 [00:28<00:24,  9.66it/s]\u001b[A\n",
            " 55% 280/512 [00:28<00:23,  9.68it/s]\u001b[A\n",
            " 55% 281/512 [00:28<00:23,  9.72it/s]\u001b[A\n",
            " 55% 282/512 [00:28<00:23,  9.73it/s]\u001b[A\n",
            " 55% 283/512 [00:28<00:23,  9.76it/s]\u001b[A\n",
            " 55% 284/512 [00:28<00:23,  9.70it/s]\u001b[A\n",
            " 56% 285/512 [00:29<00:23,  9.71it/s]\u001b[A\n",
            " 56% 286/512 [00:29<00:23,  9.78it/s]\u001b[A\n",
            " 56% 287/512 [00:29<00:23,  9.70it/s]\u001b[A\n",
            " 56% 288/512 [00:29<00:22,  9.74it/s]\u001b[A\n",
            " 56% 289/512 [00:29<00:23,  9.69it/s]\u001b[A\n",
            " 57% 290/512 [00:29<00:22,  9.65it/s]\u001b[A\n",
            " 57% 291/512 [00:29<00:22,  9.71it/s]\u001b[A\n",
            " 57% 292/512 [00:29<00:22,  9.68it/s]\u001b[A\n",
            " 57% 293/512 [00:29<00:22,  9.65it/s]\u001b[A\n",
            " 57% 294/512 [00:29<00:22,  9.68it/s]\u001b[A\n",
            " 58% 295/512 [00:30<00:22,  9.64it/s]\u001b[A\n",
            " 58% 297/512 [00:30<00:22,  9.76it/s]\u001b[A\n",
            " 58% 298/512 [00:30<00:22,  9.71it/s]\u001b[A\n",
            " 58% 299/512 [00:30<00:21,  9.69it/s]\u001b[A\n",
            " 59% 300/512 [00:30<00:21,  9.75it/s]\u001b[A\n",
            " 59% 302/512 [00:30<00:21,  9.87it/s]\u001b[A\n",
            " 59% 304/512 [00:31<00:21,  9.89it/s]\u001b[A\n",
            " 60% 305/512 [00:31<00:21,  9.83it/s]\u001b[A\n",
            " 60% 306/512 [00:31<00:21,  9.78it/s]\u001b[A\n",
            " 60% 307/512 [00:31<00:20,  9.77it/s]\u001b[A\n",
            " 60% 308/512 [00:31<00:20,  9.75it/s]\u001b[A\n",
            " 60% 309/512 [00:31<00:20,  9.71it/s]\u001b[A\n",
            " 61% 310/512 [00:31<00:20,  9.72it/s]\u001b[A\n",
            " 61% 311/512 [00:31<00:20,  9.72it/s]\u001b[A\n",
            " 61% 313/512 [00:31<00:20,  9.79it/s]\u001b[A\n",
            " 61% 314/512 [00:32<00:20,  9.75it/s]\u001b[A\n",
            " 62% 316/512 [00:32<00:19,  9.84it/s]\u001b[A\n",
            " 62% 317/512 [00:32<00:19,  9.81it/s]\u001b[A\n",
            " 62% 318/512 [00:32<00:19,  9.85it/s]\u001b[A\n",
            " 62% 319/512 [00:32<00:19,  9.85it/s]\u001b[A\n",
            " 62% 320/512 [00:32<00:19,  9.84it/s]\u001b[A\n",
            " 63% 322/512 [00:32<00:19,  9.90it/s]\u001b[A\n",
            " 63% 323/512 [00:32<00:19,  9.82it/s]\u001b[A\n",
            " 63% 324/512 [00:33<00:19,  9.75it/s]\u001b[A\n",
            " 63% 325/512 [00:33<00:19,  9.72it/s]\u001b[A\n",
            " 64% 326/512 [00:33<00:19,  9.69it/s]\u001b[A\n",
            " 64% 327/512 [00:33<00:19,  9.66it/s]\u001b[A\n",
            " 64% 328/512 [00:33<00:18,  9.70it/s]\u001b[A\n",
            " 64% 330/512 [00:33<00:18,  9.88it/s]\u001b[A\n",
            " 65% 332/512 [00:33<00:18,  9.95it/s]\u001b[A\n",
            " 65% 333/512 [00:33<00:18,  9.93it/s]\u001b[A\n",
            " 65% 334/512 [00:34<00:18,  9.87it/s]\u001b[A\n",
            " 65% 335/512 [00:34<00:18,  9.38it/s]\u001b[A\n",
            " 66% 336/512 [00:34<00:18,  9.43it/s]\u001b[A\n",
            " 66% 337/512 [00:34<00:18,  9.47it/s]\u001b[A\n",
            " 66% 338/512 [00:34<00:18,  9.50it/s]\u001b[A\n",
            " 66% 339/512 [00:34<00:17,  9.62it/s]\u001b[A\n",
            " 66% 340/512 [00:34<00:17,  9.60it/s]\u001b[A\n",
            " 67% 341/512 [00:34<00:17,  9.60it/s]\u001b[A\n",
            " 67% 343/512 [00:35<00:17,  9.73it/s]\u001b[A\n",
            " 67% 344/512 [00:35<00:17,  9.72it/s]\u001b[A\n",
            " 68% 346/512 [00:35<00:16,  9.77it/s]\u001b[A\n",
            " 68% 347/512 [00:35<00:16,  9.77it/s]\u001b[A\n",
            " 68% 348/512 [00:35<00:16,  9.77it/s]\u001b[A\n",
            " 68% 349/512 [00:35<00:16,  9.75it/s]\u001b[A\n",
            " 68% 350/512 [00:35<00:16,  9.71it/s]\u001b[A\n",
            " 69% 351/512 [00:35<00:16,  9.73it/s]\u001b[A\n",
            " 69% 352/512 [00:35<00:16,  9.67it/s]\u001b[A\n",
            " 69% 353/512 [00:36<00:16,  9.74it/s]\u001b[A\n",
            " 69% 355/512 [00:36<00:16,  9.66it/s]\u001b[A\n",
            " 70% 356/512 [00:36<00:16,  9.65it/s]\u001b[A\n",
            " 70% 357/512 [00:36<00:16,  9.67it/s]\u001b[A\n",
            " 70% 358/512 [00:36<00:16,  9.62it/s]\u001b[A\n",
            " 70% 359/512 [00:36<00:15,  9.61it/s]\u001b[A\n",
            " 71% 361/512 [00:36<00:15,  9.81it/s]\u001b[A\n",
            " 71% 362/512 [00:36<00:15,  9.82it/s]\u001b[A\n",
            " 71% 363/512 [00:37<00:15,  9.76it/s]\u001b[A\n",
            " 71% 364/512 [00:37<00:15,  9.70it/s]\u001b[A\n",
            " 71% 365/512 [00:37<00:15,  9.70it/s]\u001b[A\n",
            " 71% 366/512 [00:37<00:15,  9.68it/s]\u001b[A\n",
            " 72% 367/512 [00:37<00:14,  9.68it/s]\u001b[A\n",
            " 72% 368/512 [00:37<00:14,  9.70it/s]\u001b[A\n",
            " 72% 369/512 [00:37<00:14,  9.70it/s]\u001b[A\n",
            " 72% 370/512 [00:37<00:14,  9.67it/s]\u001b[A\n",
            " 72% 371/512 [00:37<00:14,  9.59it/s]\u001b[A\n",
            " 73% 372/512 [00:38<00:14,  9.64it/s]\u001b[A\n",
            " 73% 374/512 [00:38<00:14,  9.83it/s]\u001b[A\n",
            " 73% 375/512 [00:38<00:14,  9.72it/s]\u001b[A\n",
            " 73% 376/512 [00:38<00:13,  9.72it/s]\u001b[A\n",
            " 74% 377/512 [00:38<00:13,  9.74it/s]\u001b[A\n",
            " 74% 378/512 [00:38<00:13,  9.78it/s]\u001b[A\n",
            " 74% 380/512 [00:38<00:13,  9.83it/s]\u001b[A\n",
            " 75% 382/512 [00:39<00:13,  9.94it/s]\u001b[A\n",
            " 75% 383/512 [00:39<00:13,  9.90it/s]\u001b[A\n",
            " 75% 384/512 [00:39<00:12,  9.90it/s]\u001b[A\n",
            " 75% 385/512 [00:39<00:12,  9.93it/s]\u001b[A\n",
            " 75% 386/512 [00:39<00:12,  9.82it/s]\u001b[A\n",
            " 76% 387/512 [00:39<00:12,  9.81it/s]\u001b[A\n",
            " 76% 388/512 [00:39<00:12,  9.76it/s]\u001b[A\n",
            " 76% 389/512 [00:39<00:12,  9.74it/s]\u001b[A\n",
            " 76% 390/512 [00:39<00:12,  9.74it/s]\u001b[A\n",
            " 76% 391/512 [00:39<00:12,  9.70it/s]\u001b[A\n",
            " 77% 392/512 [00:40<00:12,  9.66it/s]\u001b[A\n",
            " 77% 393/512 [00:40<00:12,  9.72it/s]\u001b[A\n",
            " 77% 394/512 [00:40<00:12,  9.73it/s]\u001b[A\n",
            " 77% 395/512 [00:40<00:12,  9.67it/s]\u001b[A\n",
            " 77% 396/512 [00:40<00:12,  9.65it/s]\u001b[A\n",
            " 78% 398/512 [00:40<00:11,  9.92it/s]\u001b[A\n",
            " 78% 399/512 [00:40<00:11,  9.86it/s]\u001b[A\n",
            " 78% 400/512 [00:40<00:11,  9.83it/s]\u001b[A\n",
            " 78% 401/512 [00:40<00:11,  9.83it/s]\u001b[A\n",
            " 79% 402/512 [00:41<00:11,  9.72it/s]\u001b[A\n",
            " 79% 403/512 [00:41<00:11,  9.67it/s]\u001b[A\n",
            " 79% 405/512 [00:41<00:11,  9.68it/s]\u001b[A\n",
            " 79% 407/512 [00:41<00:10,  9.85it/s]\u001b[A\n",
            " 80% 409/512 [00:41<00:10, 10.03it/s]\u001b[A\n",
            " 80% 411/512 [00:41<00:10, 10.09it/s]\u001b[A\n",
            " 81% 413/512 [00:42<00:09,  9.98it/s]\u001b[A\n",
            " 81% 414/512 [00:42<00:09,  9.94it/s]\u001b[A\n",
            " 81% 415/512 [00:42<00:09,  9.87it/s]\u001b[A\n",
            " 81% 416/512 [00:42<00:09,  9.77it/s]\u001b[A\n",
            " 82% 418/512 [00:42<00:09,  9.94it/s]\u001b[A\n",
            " 82% 419/512 [00:42<00:09,  9.84it/s]\u001b[A\n",
            " 82% 420/512 [00:42<00:09,  9.82it/s]\u001b[A\n",
            " 82% 421/512 [00:42<00:09,  9.74it/s]\u001b[A\n",
            " 82% 422/512 [00:43<00:09,  9.68it/s]\u001b[A\n",
            " 83% 423/512 [00:43<00:09,  9.65it/s]\u001b[A\n",
            " 83% 425/512 [00:43<00:08,  9.72it/s]\u001b[A\n",
            " 83% 426/512 [00:43<00:08,  9.72it/s]\u001b[A\n",
            " 83% 427/512 [00:43<00:08,  9.69it/s]\u001b[A\n",
            " 84% 428/512 [00:43<00:08,  9.69it/s]\u001b[A\n",
            " 84% 429/512 [00:43<00:08,  9.76it/s]\u001b[A\n",
            " 84% 430/512 [00:43<00:08,  9.78it/s]\u001b[A\n",
            " 84% 431/512 [00:44<00:08,  9.78it/s]\u001b[A\n",
            " 85% 433/512 [00:44<00:08,  9.83it/s]\u001b[A\n",
            " 85% 434/512 [00:44<00:07,  9.77it/s]\u001b[A\n",
            " 85% 435/512 [00:44<00:07,  9.72it/s]\u001b[A\n",
            " 85% 436/512 [00:44<00:07,  9.68it/s]\u001b[A\n",
            " 85% 437/512 [00:44<00:07,  9.76it/s]\u001b[A\n",
            " 86% 438/512 [00:44<00:07,  9.78it/s]\u001b[A\n",
            " 86% 439/512 [00:44<00:07,  9.73it/s]\u001b[A\n",
            " 86% 440/512 [00:44<00:07,  9.70it/s]\u001b[A\n",
            " 86% 442/512 [00:45<00:07,  9.85it/s]\u001b[A\n",
            " 87% 443/512 [00:45<00:07,  9.82it/s]\u001b[A\n",
            " 87% 445/512 [00:45<00:06,  9.90it/s]\u001b[A\n",
            " 87% 446/512 [00:45<00:06,  9.90it/s]\u001b[A\n",
            " 87% 447/512 [00:45<00:06,  9.82it/s]\u001b[A\n",
            " 88% 448/512 [00:45<00:06,  9.76it/s]\u001b[A\n",
            " 88% 450/512 [00:45<00:06,  9.80it/s]\u001b[A\n",
            " 88% 451/512 [00:46<00:06,  9.80it/s]\u001b[A\n",
            " 88% 453/512 [00:46<00:05,  9.90it/s]\u001b[A\n",
            " 89% 454/512 [00:46<00:05,  9.90it/s]\u001b[A\n",
            " 89% 455/512 [00:46<00:05,  9.87it/s]\u001b[A\n",
            " 89% 456/512 [00:46<00:05,  9.80it/s]\u001b[A\n",
            " 89% 457/512 [00:46<00:05,  9.74it/s]\u001b[A\n",
            " 89% 458/512 [00:46<00:05,  9.67it/s]\u001b[A\n",
            " 90% 459/512 [00:46<00:05,  9.64it/s]\u001b[A\n",
            " 90% 460/512 [00:46<00:05,  9.72it/s]\u001b[A\n",
            " 90% 461/512 [00:47<00:05,  9.71it/s]\u001b[A\n",
            " 90% 462/512 [00:47<00:05,  9.77it/s]\u001b[A\n",
            " 90% 463/512 [00:47<00:04,  9.80it/s]\u001b[A\n",
            " 91% 464/512 [00:47<00:04,  9.70it/s]\u001b[A\n",
            " 91% 466/512 [00:47<00:04,  9.78it/s]\u001b[A\n",
            " 91% 467/512 [00:47<00:04,  9.78it/s]\u001b[A\n",
            " 91% 468/512 [00:47<00:04,  9.77it/s]\u001b[A\n",
            " 92% 469/512 [00:47<00:04,  9.76it/s]\u001b[A\n",
            " 92% 471/512 [00:48<00:04,  9.83it/s]\u001b[A\n",
            " 92% 472/512 [00:48<00:04,  9.82it/s]\u001b[A\n",
            " 93% 474/512 [00:48<00:03,  9.86it/s]\u001b[A\n",
            " 93% 475/512 [00:48<00:03,  9.83it/s]\u001b[A\n",
            " 93% 477/512 [00:48<00:03,  9.99it/s]\u001b[A\n",
            " 93% 478/512 [00:48<00:03,  9.96it/s]\u001b[A\n",
            " 94% 479/512 [00:48<00:03,  9.95it/s]\u001b[A\n",
            " 94% 480/512 [00:49<00:03,  9.95it/s]\u001b[A\n",
            " 94% 481/512 [00:49<00:03,  9.86it/s]\u001b[A\n",
            " 94% 482/512 [00:49<00:03,  9.79it/s]\u001b[A\n",
            " 95% 484/512 [00:49<00:02,  9.89it/s]\u001b[A\n",
            " 95% 486/512 [00:49<00:02,  9.89it/s]\u001b[A\n",
            " 95% 487/512 [00:49<00:02,  9.87it/s]\u001b[A\n",
            " 95% 488/512 [00:49<00:02,  9.86it/s]\u001b[A\n",
            " 96% 490/512 [00:50<00:02,  9.89it/s]\u001b[A\n",
            " 96% 492/512 [00:50<00:02,  9.98it/s]\u001b[A\n",
            " 96% 493/512 [00:50<00:01,  9.96it/s]\u001b[A\n",
            " 96% 494/512 [00:50<00:01,  9.92it/s]\u001b[A\n",
            " 97% 495/512 [00:50<00:01,  9.86it/s]\u001b[A\n",
            " 97% 496/512 [00:50<00:01,  9.80it/s]\u001b[A\n",
            " 97% 497/512 [00:50<00:01,  9.73it/s]\u001b[A\n",
            " 97% 498/512 [00:50<00:01,  9.62it/s]\u001b[A\n",
            " 97% 499/512 [00:50<00:01,  9.64it/s]\u001b[A\n",
            " 98% 500/512 [00:51<00:01,  9.66it/s]\u001b[A\n",
            " 98% 501/512 [00:51<00:01,  9.72it/s]\u001b[A\n",
            " 98% 503/512 [00:51<00:00,  9.79it/s]\u001b[A\n",
            " 98% 504/512 [00:51<00:00,  9.81it/s]\u001b[A\n",
            " 99% 505/512 [00:51<00:00,  9.76it/s]\u001b[A\n",
            " 99% 506/512 [00:51<00:00,  9.75it/s]\u001b[A\n",
            " 99% 507/512 [00:51<00:00,  9.76it/s]\u001b[A\n",
            " 99% 508/512 [00:51<00:00,  9.73it/s]\u001b[A\n",
            " 99% 509/512 [00:51<00:00,  9.73it/s]\u001b[A\n",
            "100% 510/512 [00:52<00:00,  9.78it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.2073028087615967, 'eval_runtime': 52.3851, 'eval_samples_per_second': 9.774, 'eval_steps_per_second': 9.774, 'epoch': 2.12}\n",
            " 43% 100/235 [07:00<08:13,  3.65s/it]\n",
            "100% 512/512 [00:52<00:00,  9.90it/s]\u001b[A\n",
            "{'loss': 0.0319, 'learning_rate': 5.792422552377152e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0329, 'learning_rate': 5.1037896589754134e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0276, 'learning_rate': 4.413172001833323e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0239, 'learning_rate': 3.73377622309494e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0241, 'learning_rate': 3.078594369562417e-05, 'epoch': 3.17}\n",
            "{'loss': 0.0232, 'learning_rate': 2.460155446524573e-05, 'epoch': 3.39}\n",
            "{'loss': 0.0201, 'learning_rate': 1.8902858263019746e-05, 'epoch': 3.6}\n",
            "{'loss': 0.0271, 'learning_rate': 1.3798830932022617e-05, 'epoch': 3.81}\n",
            "{'loss': 0.024, 'learning_rate': 9.387076496357805e-06, 'epoch': 4.02}\n",
            "{'loss': 0.0168, 'learning_rate': 5.751960684959046e-06, 'epoch': 4.23}\n",
            " 85% 200/235 [13:06<02:07,  3.65s/it][INFO|trainer.py:3081] 2023-09-25 02:31:54,370 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3083] 2023-09-25 02:31:54,370 >>   Num examples = 512\n",
            "[INFO|trainer.py:3086] 2023-09-25 02:31:54,370 >>   Batch size = 1\n",
            "\n",
            "  0% 0/512 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/512 [00:00<00:26, 19.45it/s]\u001b[A\n",
            "  1% 4/512 [00:00<00:40, 12.51it/s]\u001b[A\n",
            "  1% 6/512 [00:00<00:46, 11.00it/s]\u001b[A\n",
            "  2% 8/512 [00:00<00:48, 10.43it/s]\u001b[A\n",
            "  2% 10/512 [00:00<00:49, 10.11it/s]\u001b[A\n",
            "  2% 12/512 [00:01<00:50,  9.94it/s]\u001b[A\n",
            "  3% 14/512 [00:01<00:50,  9.86it/s]\u001b[A\n",
            "  3% 16/512 [00:01<00:49,  9.93it/s]\u001b[A\n",
            "  4% 18/512 [00:01<00:50,  9.82it/s]\u001b[A\n",
            "  4% 19/512 [00:01<00:50,  9.70it/s]\u001b[A\n",
            "  4% 20/512 [00:01<00:50,  9.75it/s]\u001b[A\n",
            "  4% 21/512 [00:02<00:50,  9.74it/s]\u001b[A\n",
            "  4% 22/512 [00:02<00:50,  9.72it/s]\u001b[A\n",
            "  4% 23/512 [00:02<00:50,  9.75it/s]\u001b[A\n",
            "  5% 24/512 [00:02<00:50,  9.68it/s]\u001b[A\n",
            "  5% 25/512 [00:02<00:50,  9.69it/s]\u001b[A\n",
            "  5% 26/512 [00:02<00:50,  9.66it/s]\u001b[A\n",
            "  5% 28/512 [00:02<00:49,  9.74it/s]\u001b[A\n",
            "  6% 29/512 [00:02<00:50,  9.56it/s]\u001b[A\n",
            "  6% 31/512 [00:03<00:49,  9.71it/s]\u001b[A\n",
            "  6% 32/512 [00:03<00:49,  9.67it/s]\u001b[A\n",
            "  7% 34/512 [00:03<00:48,  9.76it/s]\u001b[A\n",
            "  7% 36/512 [00:03<00:48,  9.79it/s]\u001b[A\n",
            "  7% 37/512 [00:03<00:48,  9.80it/s]\u001b[A\n",
            "  8% 39/512 [00:03<00:48,  9.84it/s]\u001b[A\n",
            "  8% 40/512 [00:04<00:48,  9.72it/s]\u001b[A\n",
            "  8% 41/512 [00:04<00:48,  9.73it/s]\u001b[A\n",
            "  8% 42/512 [00:04<00:48,  9.76it/s]\u001b[A\n",
            "  8% 43/512 [00:04<00:48,  9.75it/s]\u001b[A\n",
            "  9% 44/512 [00:04<00:48,  9.69it/s]\u001b[A\n",
            "  9% 45/512 [00:04<00:48,  9.68it/s]\u001b[A\n",
            "  9% 46/512 [00:04<00:48,  9.64it/s]\u001b[A\n",
            "  9% 47/512 [00:04<00:48,  9.57it/s]\u001b[A\n",
            "  9% 48/512 [00:04<00:48,  9.58it/s]\u001b[A\n",
            " 10% 49/512 [00:04<00:48,  9.58it/s]\u001b[A\n",
            " 10% 50/512 [00:05<00:48,  9.58it/s]\u001b[A\n",
            " 10% 51/512 [00:05<00:47,  9.70it/s]\u001b[A\n",
            " 10% 52/512 [00:05<00:47,  9.69it/s]\u001b[A\n",
            " 10% 53/512 [00:05<00:47,  9.74it/s]\u001b[A\n",
            " 11% 54/512 [00:05<00:47,  9.71it/s]\u001b[A\n",
            " 11% 55/512 [00:05<00:47,  9.64it/s]\u001b[A\n",
            " 11% 56/512 [00:05<00:46,  9.72it/s]\u001b[A\n",
            " 11% 57/512 [00:05<00:47,  9.63it/s]\u001b[A\n",
            " 11% 58/512 [00:05<00:47,  9.61it/s]\u001b[A\n",
            " 12% 59/512 [00:05<00:47,  9.56it/s]\u001b[A\n",
            " 12% 60/512 [00:06<00:47,  9.56it/s]\u001b[A\n",
            " 12% 61/512 [00:06<00:46,  9.64it/s]\u001b[A\n",
            " 12% 62/512 [00:06<00:46,  9.64it/s]\u001b[A\n",
            " 12% 64/512 [00:06<00:45,  9.79it/s]\u001b[A\n",
            " 13% 65/512 [00:06<00:45,  9.77it/s]\u001b[A\n",
            " 13% 66/512 [00:06<00:45,  9.72it/s]\u001b[A\n",
            " 13% 67/512 [00:06<00:45,  9.69it/s]\u001b[A\n",
            " 13% 68/512 [00:06<00:45,  9.73it/s]\u001b[A\n",
            " 13% 69/512 [00:07<00:45,  9.64it/s]\u001b[A\n",
            " 14% 71/512 [00:07<00:44,  9.92it/s]\u001b[A\n",
            " 14% 73/512 [00:07<00:43,  9.98it/s]\u001b[A\n",
            " 14% 74/512 [00:07<00:44,  9.93it/s]\u001b[A\n",
            " 15% 75/512 [00:07<00:44,  9.92it/s]\u001b[A\n",
            " 15% 76/512 [00:07<00:44,  9.85it/s]\u001b[A\n",
            " 15% 77/512 [00:07<00:44,  9.82it/s]\u001b[A\n",
            " 15% 78/512 [00:07<00:44,  9.86it/s]\u001b[A\n",
            " 15% 79/512 [00:08<00:44,  9.78it/s]\u001b[A\n",
            " 16% 80/512 [00:08<00:44,  9.72it/s]\u001b[A\n",
            " 16% 81/512 [00:08<00:44,  9.68it/s]\u001b[A\n",
            " 16% 82/512 [00:08<00:44,  9.64it/s]\u001b[A\n",
            " 16% 83/512 [00:08<00:44,  9.71it/s]\u001b[A\n",
            " 16% 84/512 [00:08<00:44,  9.66it/s]\u001b[A\n",
            " 17% 86/512 [00:08<00:43,  9.77it/s]\u001b[A\n",
            " 17% 87/512 [00:08<00:43,  9.71it/s]\u001b[A\n",
            " 17% 88/512 [00:08<00:43,  9.75it/s]\u001b[A\n",
            " 17% 89/512 [00:09<00:43,  9.75it/s]\u001b[A\n",
            " 18% 90/512 [00:09<00:43,  9.79it/s]\u001b[A\n",
            " 18% 91/512 [00:09<00:42,  9.85it/s]\u001b[A\n",
            " 18% 93/512 [00:09<00:42,  9.86it/s]\u001b[A\n",
            " 18% 94/512 [00:09<00:42,  9.79it/s]\u001b[A\n",
            " 19% 95/512 [00:09<00:42,  9.72it/s]\u001b[A\n",
            " 19% 96/512 [00:09<00:42,  9.73it/s]\u001b[A\n",
            " 19% 97/512 [00:09<00:42,  9.74it/s]\u001b[A\n",
            " 19% 98/512 [00:09<00:42,  9.74it/s]\u001b[A\n",
            " 19% 99/512 [00:10<00:42,  9.71it/s]\u001b[A\n",
            " 20% 100/512 [00:10<00:42,  9.74it/s]\u001b[A\n",
            " 20% 101/512 [00:10<00:42,  9.68it/s]\u001b[A\n",
            " 20% 102/512 [00:10<00:42,  9.69it/s]\u001b[A\n",
            " 20% 104/512 [00:10<00:41,  9.76it/s]\u001b[A\n",
            " 21% 105/512 [00:10<00:41,  9.69it/s]\u001b[A\n",
            " 21% 106/512 [00:10<00:42,  9.66it/s]\u001b[A\n",
            " 21% 107/512 [00:10<00:42,  9.62it/s]\u001b[A\n",
            " 21% 108/512 [00:11<00:41,  9.66it/s]\u001b[A\n",
            " 21% 109/512 [00:11<00:41,  9.64it/s]\u001b[A\n",
            " 21% 110/512 [00:11<00:41,  9.66it/s]\u001b[A\n",
            " 22% 111/512 [00:11<00:41,  9.66it/s]\u001b[A\n",
            " 22% 112/512 [00:11<00:41,  9.63it/s]\u001b[A\n",
            " 22% 113/512 [00:11<00:41,  9.69it/s]\u001b[A\n",
            " 22% 114/512 [00:11<00:41,  9.69it/s]\u001b[A\n",
            " 23% 116/512 [00:11<00:40,  9.73it/s]\u001b[A\n",
            " 23% 117/512 [00:11<00:40,  9.75it/s]\u001b[A\n",
            " 23% 118/512 [00:12<00:40,  9.75it/s]\u001b[A\n",
            " 23% 120/512 [00:12<00:39,  9.87it/s]\u001b[A\n",
            " 24% 122/512 [00:12<00:39,  9.87it/s]\u001b[A\n",
            " 24% 124/512 [00:12<00:39,  9.92it/s]\u001b[A\n",
            " 24% 125/512 [00:12<00:39,  9.84it/s]\u001b[A\n",
            " 25% 126/512 [00:12<00:39,  9.84it/s]\u001b[A\n",
            " 25% 128/512 [00:13<00:39,  9.83it/s]\u001b[A\n",
            " 25% 129/512 [00:13<00:39,  9.80it/s]\u001b[A\n",
            " 25% 130/512 [00:13<00:39,  9.77it/s]\u001b[A\n",
            " 26% 131/512 [00:13<00:39,  9.73it/s]\u001b[A\n",
            " 26% 132/512 [00:13<00:39,  9.69it/s]\u001b[A\n",
            " 26% 133/512 [00:13<00:39,  9.68it/s]\u001b[A\n",
            " 26% 134/512 [00:13<00:39,  9.68it/s]\u001b[A\n",
            " 27% 136/512 [00:13<00:38,  9.78it/s]\u001b[A\n",
            " 27% 137/512 [00:13<00:38,  9.70it/s]\u001b[A\n",
            " 27% 139/512 [00:14<00:37,  9.91it/s]\u001b[A\n",
            " 28% 141/512 [00:14<00:36, 10.04it/s]\u001b[A\n",
            " 28% 142/512 [00:14<00:36, 10.03it/s]\u001b[A\n",
            " 28% 144/512 [00:14<00:36, 10.05it/s]\u001b[A\n",
            " 29% 146/512 [00:14<00:36,  9.90it/s]\u001b[A\n",
            " 29% 147/512 [00:14<00:37,  9.83it/s]\u001b[A\n",
            " 29% 148/512 [00:15<00:36,  9.84it/s]\u001b[A\n",
            " 29% 149/512 [00:15<00:37,  9.81it/s]\u001b[A\n",
            " 29% 150/512 [00:15<00:37,  9.78it/s]\u001b[A\n",
            " 29% 151/512 [00:15<00:36,  9.80it/s]\u001b[A\n",
            " 30% 152/512 [00:15<00:36,  9.73it/s]\u001b[A\n",
            " 30% 153/512 [00:15<00:37,  9.68it/s]\u001b[A\n",
            " 30% 154/512 [00:15<00:37,  9.63it/s]\u001b[A\n",
            " 30% 156/512 [00:15<00:36,  9.80it/s]\u001b[A\n",
            " 31% 157/512 [00:16<00:36,  9.78it/s]\u001b[A\n",
            " 31% 158/512 [00:16<00:36,  9.78it/s]\u001b[A\n",
            " 31% 159/512 [00:16<00:36,  9.78it/s]\u001b[A\n",
            " 31% 160/512 [00:16<00:35,  9.81it/s]\u001b[A\n",
            " 31% 161/512 [00:16<00:35,  9.75it/s]\u001b[A\n",
            " 32% 162/512 [00:16<00:35,  9.77it/s]\u001b[A\n",
            " 32% 163/512 [00:16<00:35,  9.83it/s]\u001b[A\n",
            " 32% 164/512 [00:16<00:35,  9.78it/s]\u001b[A\n",
            " 32% 165/512 [00:16<00:35,  9.76it/s]\u001b[A\n",
            " 32% 166/512 [00:16<00:35,  9.75it/s]\u001b[A\n",
            " 33% 167/512 [00:17<00:35,  9.80it/s]\u001b[A\n",
            " 33% 168/512 [00:17<00:35,  9.78it/s]\u001b[A\n",
            " 33% 169/512 [00:17<00:35,  9.78it/s]\u001b[A\n",
            " 33% 170/512 [00:17<00:35,  9.77it/s]\u001b[A\n",
            " 33% 171/512 [00:17<00:34,  9.83it/s]\u001b[A\n",
            " 34% 172/512 [00:17<00:34,  9.75it/s]\u001b[A\n",
            " 34% 173/512 [00:17<00:34,  9.71it/s]\u001b[A\n",
            " 34% 174/512 [00:17<00:35,  9.65it/s]\u001b[A\n",
            " 34% 176/512 [00:17<00:34,  9.76it/s]\u001b[A\n",
            " 35% 177/512 [00:18<00:34,  9.75it/s]\u001b[A\n",
            " 35% 179/512 [00:18<00:33,  9.82it/s]\u001b[A\n",
            " 35% 180/512 [00:18<00:33,  9.84it/s]\u001b[A\n",
            " 35% 181/512 [00:18<00:33,  9.79it/s]\u001b[A\n",
            " 36% 182/512 [00:18<00:33,  9.78it/s]\u001b[A\n",
            " 36% 183/512 [00:18<00:33,  9.69it/s]\u001b[A\n",
            " 36% 184/512 [00:18<00:33,  9.77it/s]\u001b[A\n",
            " 36% 185/512 [00:18<00:33,  9.82it/s]\u001b[A\n",
            " 36% 186/512 [00:18<00:33,  9.86it/s]\u001b[A\n",
            " 37% 187/512 [00:19<00:32,  9.89it/s]\u001b[A\n",
            " 37% 188/512 [00:19<00:32,  9.85it/s]\u001b[A\n",
            " 37% 189/512 [00:19<00:33,  9.77it/s]\u001b[A\n",
            " 37% 190/512 [00:19<00:32,  9.77it/s]\u001b[A\n",
            " 38% 192/512 [00:19<00:32,  9.87it/s]\u001b[A\n",
            " 38% 193/512 [00:19<00:32,  9.82it/s]\u001b[A\n",
            " 38% 194/512 [00:19<00:32,  9.84it/s]\u001b[A\n",
            " 38% 195/512 [00:19<00:32,  9.81it/s]\u001b[A\n",
            " 38% 196/512 [00:19<00:32,  9.79it/s]\u001b[A\n",
            " 38% 197/512 [00:20<00:32,  9.78it/s]\u001b[A\n",
            " 39% 198/512 [00:20<00:32,  9.80it/s]\u001b[A\n",
            " 39% 199/512 [00:20<00:32,  9.74it/s]\u001b[A\n",
            " 39% 200/512 [00:20<00:31,  9.79it/s]\u001b[A\n",
            " 39% 201/512 [00:20<00:31,  9.84it/s]\u001b[A\n",
            " 39% 202/512 [00:20<00:31,  9.84it/s]\u001b[A\n",
            " 40% 203/512 [00:20<00:31,  9.75it/s]\u001b[A\n",
            " 40% 204/512 [00:20<00:31,  9.78it/s]\u001b[A\n",
            " 40% 205/512 [00:20<00:31,  9.79it/s]\u001b[A\n",
            " 40% 207/512 [00:21<00:30,  9.99it/s]\u001b[A\n",
            " 41% 209/512 [00:21<00:30, 10.01it/s]\u001b[A\n",
            " 41% 210/512 [00:21<00:30,  9.93it/s]\u001b[A\n",
            " 41% 212/512 [00:21<00:30,  9.97it/s]\u001b[A\n",
            " 42% 213/512 [00:21<00:30,  9.95it/s]\u001b[A\n",
            " 42% 215/512 [00:21<00:29, 10.08it/s]\u001b[A\n",
            " 42% 217/512 [00:22<00:29, 10.00it/s]\u001b[A\n",
            " 43% 218/512 [00:22<00:29,  9.97it/s]\u001b[A\n",
            " 43% 220/512 [00:22<00:29,  9.93it/s]\u001b[A\n",
            " 43% 221/512 [00:22<00:29,  9.86it/s]\u001b[A\n",
            " 43% 222/512 [00:22<00:29,  9.84it/s]\u001b[A\n",
            " 44% 224/512 [00:22<00:29,  9.92it/s]\u001b[A\n",
            " 44% 225/512 [00:22<00:28,  9.93it/s]\u001b[A\n",
            " 44% 226/512 [00:23<00:28,  9.93it/s]\u001b[A\n",
            " 44% 227/512 [00:23<00:28,  9.91it/s]\u001b[A\n",
            " 45% 228/512 [00:23<00:28,  9.82it/s]\u001b[A\n",
            " 45% 229/512 [00:23<00:29,  9.75it/s]\u001b[A\n",
            " 45% 231/512 [00:23<00:28,  9.84it/s]\u001b[A\n",
            " 45% 232/512 [00:23<00:28,  9.80it/s]\u001b[A\n",
            " 46% 233/512 [00:23<00:28,  9.74it/s]\u001b[A\n",
            " 46% 234/512 [00:23<00:28,  9.69it/s]\u001b[A\n",
            " 46% 235/512 [00:23<00:28,  9.65it/s]\u001b[A\n",
            " 46% 236/512 [00:24<00:28,  9.63it/s]\u001b[A\n",
            " 46% 237/512 [00:24<00:28,  9.60it/s]\u001b[A\n",
            " 46% 238/512 [00:24<00:28,  9.67it/s]\u001b[A\n",
            " 47% 239/512 [00:24<00:28,  9.65it/s]\u001b[A\n",
            " 47% 240/512 [00:24<00:28,  9.63it/s]\u001b[A\n",
            " 47% 241/512 [00:24<00:28,  9.60it/s]\u001b[A\n",
            " 47% 242/512 [00:24<00:28,  9.60it/s]\u001b[A\n",
            " 47% 243/512 [00:24<00:28,  9.56it/s]\u001b[A\n",
            " 48% 244/512 [00:24<00:27,  9.66it/s]\u001b[A\n",
            " 48% 245/512 [00:24<00:27,  9.65it/s]\u001b[A\n",
            " 48% 246/512 [00:25<00:27,  9.69it/s]\u001b[A\n",
            " 48% 248/512 [00:25<00:26,  9.87it/s]\u001b[A\n",
            " 49% 249/512 [00:25<00:26,  9.89it/s]\u001b[A\n",
            " 49% 251/512 [00:25<00:26,  9.89it/s]\u001b[A\n",
            " 49% 252/512 [00:25<00:26,  9.83it/s]\u001b[A\n",
            " 49% 253/512 [00:25<00:26,  9.84it/s]\u001b[A\n",
            " 50% 254/512 [00:25<00:26,  9.82it/s]\u001b[A\n",
            " 50% 255/512 [00:25<00:26,  9.71it/s]\u001b[A\n",
            " 50% 256/512 [00:26<00:26,  9.72it/s]\u001b[A\n",
            " 50% 257/512 [00:26<00:26,  9.73it/s]\u001b[A\n",
            " 51% 259/512 [00:26<00:25,  9.85it/s]\u001b[A\n",
            " 51% 260/512 [00:26<00:25,  9.84it/s]\u001b[A\n",
            " 51% 261/512 [00:26<00:25,  9.83it/s]\u001b[A\n",
            " 51% 262/512 [00:26<00:25,  9.77it/s]\u001b[A\n",
            " 51% 263/512 [00:26<00:25,  9.76it/s]\u001b[A\n",
            " 52% 264/512 [00:26<00:25,  9.76it/s]\u001b[A\n",
            " 52% 265/512 [00:27<00:25,  9.71it/s]\u001b[A\n",
            " 52% 266/512 [00:27<00:25,  9.71it/s]\u001b[A\n",
            " 52% 267/512 [00:27<00:25,  9.76it/s]\u001b[A\n",
            " 53% 269/512 [00:27<00:24,  9.90it/s]\u001b[A\n",
            " 53% 270/512 [00:27<00:24,  9.83it/s]\u001b[A\n",
            " 53% 271/512 [00:27<00:24,  9.80it/s]\u001b[A\n",
            " 53% 272/512 [00:27<00:24,  9.85it/s]\u001b[A\n",
            " 53% 273/512 [00:27<00:24,  9.78it/s]\u001b[A\n",
            " 54% 275/512 [00:28<00:24,  9.81it/s]\u001b[A\n",
            " 54% 276/512 [00:28<00:24,  9.78it/s]\u001b[A\n",
            " 54% 277/512 [00:28<00:23,  9.80it/s]\u001b[A\n",
            " 54% 278/512 [00:28<00:24,  9.73it/s]\u001b[A\n",
            " 54% 279/512 [00:28<00:24,  9.69it/s]\u001b[A\n",
            " 55% 280/512 [00:28<00:24,  9.58it/s]\u001b[A\n",
            " 55% 281/512 [00:28<00:23,  9.65it/s]\u001b[A\n",
            " 55% 282/512 [00:28<00:23,  9.67it/s]\u001b[A\n",
            " 55% 283/512 [00:28<00:23,  9.72it/s]\u001b[A\n",
            " 55% 284/512 [00:28<00:23,  9.65it/s]\u001b[A\n",
            " 56% 285/512 [00:29<00:23,  9.69it/s]\u001b[A\n",
            " 56% 287/512 [00:29<00:23,  9.77it/s]\u001b[A\n",
            " 56% 288/512 [00:29<00:22,  9.78it/s]\u001b[A\n",
            " 56% 289/512 [00:29<00:22,  9.72it/s]\u001b[A\n",
            " 57% 290/512 [00:29<00:22,  9.68it/s]\u001b[A\n",
            " 57% 291/512 [00:29<00:22,  9.64it/s]\u001b[A\n",
            " 57% 292/512 [00:29<00:22,  9.60it/s]\u001b[A\n",
            " 57% 293/512 [00:29<00:22,  9.58it/s]\u001b[A\n",
            " 57% 294/512 [00:30<00:22,  9.62it/s]\u001b[A\n",
            " 58% 295/512 [00:30<00:22,  9.60it/s]\u001b[A\n",
            " 58% 297/512 [00:30<00:22,  9.70it/s]\u001b[A\n",
            " 58% 298/512 [00:30<00:22,  9.70it/s]\u001b[A\n",
            " 58% 299/512 [00:30<00:22,  9.60it/s]\u001b[A\n",
            " 59% 300/512 [00:30<00:21,  9.64it/s]\u001b[A\n",
            " 59% 301/512 [00:30<00:21,  9.71it/s]\u001b[A\n",
            " 59% 302/512 [00:30<00:21,  9.68it/s]\u001b[A\n",
            " 59% 303/512 [00:30<00:21,  9.73it/s]\u001b[A\n",
            " 59% 304/512 [00:31<00:21,  9.66it/s]\u001b[A\n",
            " 60% 305/512 [00:31<00:21,  9.68it/s]\u001b[A\n",
            " 60% 306/512 [00:31<00:21,  9.65it/s]\u001b[A\n",
            " 60% 307/512 [00:31<00:21,  9.67it/s]\u001b[A\n",
            " 60% 308/512 [00:31<00:21,  9.69it/s]\u001b[A\n",
            " 60% 309/512 [00:31<00:21,  9.62it/s]\u001b[A\n",
            " 61% 310/512 [00:31<00:20,  9.66it/s]\u001b[A\n",
            " 61% 311/512 [00:31<00:20,  9.68it/s]\u001b[A\n",
            " 61% 313/512 [00:31<00:20,  9.79it/s]\u001b[A\n",
            " 61% 314/512 [00:32<00:20,  9.75it/s]\u001b[A\n",
            " 62% 316/512 [00:32<00:19,  9.86it/s]\u001b[A\n",
            " 62% 317/512 [00:32<00:19,  9.82it/s]\u001b[A\n",
            " 62% 318/512 [00:32<00:19,  9.84it/s]\u001b[A\n",
            " 62% 319/512 [00:32<00:20,  9.54it/s]\u001b[A\n",
            " 62% 320/512 [00:32<00:19,  9.62it/s]\u001b[A\n",
            " 63% 322/512 [00:32<00:19,  9.77it/s]\u001b[A\n",
            " 63% 323/512 [00:32<00:19,  9.74it/s]\u001b[A\n",
            " 63% 324/512 [00:33<00:19,  9.71it/s]\u001b[A\n",
            " 63% 325/512 [00:33<00:19,  9.72it/s]\u001b[A\n",
            " 64% 326/512 [00:33<00:19,  9.70it/s]\u001b[A\n",
            " 64% 327/512 [00:33<00:19,  9.68it/s]\u001b[A\n",
            " 64% 328/512 [00:33<00:18,  9.74it/s]\u001b[A\n",
            " 64% 330/512 [00:33<00:18,  9.94it/s]\u001b[A\n",
            " 65% 332/512 [00:33<00:17, 10.00it/s]\u001b[A\n",
            " 65% 333/512 [00:34<00:17, 10.00it/s]\u001b[A\n",
            " 65% 334/512 [00:34<00:17,  9.98it/s]\u001b[A\n",
            " 65% 335/512 [00:34<00:17,  9.88it/s]\u001b[A\n",
            " 66% 336/512 [00:34<00:17,  9.78it/s]\u001b[A\n",
            " 66% 337/512 [00:34<00:18,  9.72it/s]\u001b[A\n",
            " 66% 338/512 [00:34<00:17,  9.75it/s]\u001b[A\n",
            " 66% 339/512 [00:34<00:17,  9.79it/s]\u001b[A\n",
            " 66% 340/512 [00:34<00:17,  9.70it/s]\u001b[A\n",
            " 67% 341/512 [00:34<00:17,  9.63it/s]\u001b[A\n",
            " 67% 343/512 [00:35<00:17,  9.75it/s]\u001b[A\n",
            " 67% 344/512 [00:35<00:17,  9.76it/s]\u001b[A\n",
            " 68% 346/512 [00:35<00:16,  9.78it/s]\u001b[A\n",
            " 68% 347/512 [00:35<00:16,  9.77it/s]\u001b[A\n",
            " 68% 348/512 [00:35<00:16,  9.75it/s]\u001b[A\n",
            " 68% 349/512 [00:35<00:16,  9.72it/s]\u001b[A\n",
            " 68% 350/512 [00:35<00:16,  9.66it/s]\u001b[A\n",
            " 69% 351/512 [00:35<00:16,  9.67it/s]\u001b[A\n",
            " 69% 352/512 [00:35<00:16,  9.69it/s]\u001b[A\n",
            " 69% 353/512 [00:36<00:16,  9.75it/s]\u001b[A\n",
            " 69% 355/512 [00:36<00:15, 10.00it/s]\u001b[A\n",
            " 70% 356/512 [00:36<00:15,  9.91it/s]\u001b[A\n",
            " 70% 357/512 [00:36<00:15,  9.86it/s]\u001b[A\n",
            " 70% 358/512 [00:36<00:15,  9.79it/s]\u001b[A\n",
            " 70% 359/512 [00:36<00:15,  9.65it/s]\u001b[A\n",
            " 71% 361/512 [00:36<00:15,  9.93it/s]\u001b[A\n",
            " 71% 362/512 [00:36<00:15,  9.94it/s]\u001b[A\n",
            " 71% 363/512 [00:37<00:15,  9.87it/s]\u001b[A\n",
            " 71% 364/512 [00:37<00:15,  9.82it/s]\u001b[A\n",
            " 71% 366/512 [00:37<00:14,  9.83it/s]\u001b[A\n",
            " 72% 367/512 [00:37<00:14,  9.75it/s]\u001b[A\n",
            " 72% 368/512 [00:37<00:14,  9.76it/s]\u001b[A\n",
            " 72% 369/512 [00:37<00:14,  9.76it/s]\u001b[A\n",
            " 72% 370/512 [00:37<00:14,  9.69it/s]\u001b[A\n",
            " 72% 371/512 [00:37<00:14,  9.64it/s]\u001b[A\n",
            " 73% 372/512 [00:38<00:14,  9.60it/s]\u001b[A\n",
            " 73% 374/512 [00:38<00:14,  9.82it/s]\u001b[A\n",
            " 73% 375/512 [00:38<00:13,  9.83it/s]\u001b[A\n",
            " 73% 376/512 [00:38<00:13,  9.80it/s]\u001b[A\n",
            " 74% 377/512 [00:38<00:13,  9.79it/s]\u001b[A\n",
            " 74% 378/512 [00:38<00:13,  9.75it/s]\u001b[A\n",
            " 74% 379/512 [00:38<00:13,  9.77it/s]\u001b[A\n",
            " 74% 380/512 [00:38<00:13,  9.76it/s]\u001b[A\n",
            " 75% 382/512 [00:39<00:13,  9.87it/s]\u001b[A\n",
            " 75% 383/512 [00:39<00:13,  9.86it/s]\u001b[A\n",
            " 75% 384/512 [00:39<00:12,  9.89it/s]\u001b[A\n",
            " 75% 385/512 [00:39<00:12,  9.86it/s]\u001b[A\n",
            " 75% 386/512 [00:39<00:12,  9.79it/s]\u001b[A\n",
            " 76% 387/512 [00:39<00:12,  9.77it/s]\u001b[A\n",
            " 76% 388/512 [00:39<00:12,  9.72it/s]\u001b[A\n",
            " 76% 389/512 [00:39<00:12,  9.72it/s]\u001b[A\n",
            " 76% 390/512 [00:39<00:12,  9.72it/s]\u001b[A\n",
            " 76% 391/512 [00:39<00:12,  9.65it/s]\u001b[A\n",
            " 77% 392/512 [00:40<00:12,  9.63it/s]\u001b[A\n",
            " 77% 393/512 [00:40<00:12,  9.69it/s]\u001b[A\n",
            " 77% 394/512 [00:40<00:12,  9.72it/s]\u001b[A\n",
            " 77% 395/512 [00:40<00:12,  9.69it/s]\u001b[A\n",
            " 77% 396/512 [00:40<00:12,  9.64it/s]\u001b[A\n",
            " 78% 397/512 [00:40<00:11,  9.72it/s]\u001b[A\n",
            " 78% 399/512 [00:40<00:11,  9.85it/s]\u001b[A\n",
            " 78% 400/512 [00:40<00:11,  9.78it/s]\u001b[A\n",
            " 78% 401/512 [00:40<00:11,  9.76it/s]\u001b[A\n",
            " 79% 402/512 [00:41<00:11,  9.71it/s]\u001b[A\n",
            " 79% 403/512 [00:41<00:11,  9.60it/s]\u001b[A\n",
            " 79% 405/512 [00:41<00:11,  9.73it/s]\u001b[A\n",
            " 79% 407/512 [00:41<00:10,  9.81it/s]\u001b[A\n",
            " 80% 409/512 [00:41<00:10,  9.84it/s]\u001b[A\n",
            " 80% 411/512 [00:41<00:10,  9.85it/s]\u001b[A\n",
            " 80% 412/512 [00:42<00:10,  9.78it/s]\u001b[A\n",
            " 81% 414/512 [00:42<00:09,  9.82it/s]\u001b[A\n",
            " 81% 415/512 [00:42<00:09,  9.79it/s]\u001b[A\n",
            " 81% 416/512 [00:42<00:09,  9.74it/s]\u001b[A\n",
            " 82% 418/512 [00:42<00:09,  9.93it/s]\u001b[A\n",
            " 82% 419/512 [00:42<00:09,  9.86it/s]\u001b[A\n",
            " 82% 420/512 [00:42<00:09,  9.86it/s]\u001b[A\n",
            " 82% 421/512 [00:43<00:09,  9.78it/s]\u001b[A\n",
            " 82% 422/512 [00:43<00:09,  9.73it/s]\u001b[A\n",
            " 83% 423/512 [00:43<00:09,  9.69it/s]\u001b[A\n",
            " 83% 424/512 [00:43<00:09,  9.76it/s]\u001b[A\n",
            " 83% 425/512 [00:43<00:08,  9.73it/s]\u001b[A\n",
            " 83% 426/512 [00:43<00:08,  9.69it/s]\u001b[A\n",
            " 83% 427/512 [00:43<00:08,  9.68it/s]\u001b[A\n",
            " 84% 428/512 [00:43<00:08,  9.63it/s]\u001b[A\n",
            " 84% 429/512 [00:43<00:08,  9.49it/s]\u001b[A\n",
            " 84% 430/512 [00:43<00:08,  9.53it/s]\u001b[A\n",
            " 84% 431/512 [00:44<00:08,  9.58it/s]\u001b[A\n",
            " 84% 432/512 [00:44<00:08,  9.69it/s]\u001b[A\n",
            " 85% 433/512 [00:44<00:08,  9.71it/s]\u001b[A\n",
            " 85% 434/512 [00:44<00:08,  9.66it/s]\u001b[A\n",
            " 85% 435/512 [00:44<00:08,  9.59it/s]\u001b[A\n",
            " 85% 436/512 [00:44<00:07,  9.57it/s]\u001b[A\n",
            " 85% 437/512 [00:44<00:07,  9.65it/s]\u001b[A\n",
            " 86% 438/512 [00:44<00:07,  9.64it/s]\u001b[A\n",
            " 86% 439/512 [00:44<00:07,  9.59it/s]\u001b[A\n",
            " 86% 440/512 [00:44<00:07,  9.54it/s]\u001b[A\n",
            " 86% 442/512 [00:45<00:07,  9.72it/s]\u001b[A\n",
            " 87% 443/512 [00:45<00:07,  9.73it/s]\u001b[A\n",
            " 87% 445/512 [00:45<00:06,  9.80it/s]\u001b[A\n",
            " 87% 446/512 [00:45<00:06,  9.83it/s]\u001b[A\n",
            " 87% 447/512 [00:45<00:06,  9.74it/s]\u001b[A\n",
            " 88% 448/512 [00:45<00:06,  9.70it/s]\u001b[A\n",
            " 88% 450/512 [00:46<00:06,  9.79it/s]\u001b[A\n",
            " 88% 451/512 [00:46<00:06,  9.82it/s]\u001b[A\n",
            " 88% 453/512 [00:46<00:05,  9.92it/s]\u001b[A\n",
            " 89% 454/512 [00:46<00:05,  9.87it/s]\u001b[A\n",
            " 89% 455/512 [00:46<00:05,  9.84it/s]\u001b[A\n",
            " 89% 456/512 [00:46<00:05,  9.78it/s]\u001b[A\n",
            " 89% 457/512 [00:46<00:05,  9.76it/s]\u001b[A\n",
            " 89% 458/512 [00:46<00:05,  9.69it/s]\u001b[A\n",
            " 90% 459/512 [00:46<00:05,  9.65it/s]\u001b[A\n",
            " 90% 460/512 [00:47<00:05,  9.73it/s]\u001b[A\n",
            " 90% 461/512 [00:47<00:05,  9.76it/s]\u001b[A\n",
            " 90% 462/512 [00:47<00:05,  9.82it/s]\u001b[A\n",
            " 90% 463/512 [00:47<00:04,  9.86it/s]\u001b[A\n",
            " 91% 464/512 [00:47<00:04,  9.76it/s]\u001b[A\n",
            " 91% 465/512 [00:47<00:04,  9.83it/s]\u001b[A\n",
            " 91% 466/512 [00:47<00:04,  9.75it/s]\u001b[A\n",
            " 91% 467/512 [00:47<00:04,  9.73it/s]\u001b[A\n",
            " 91% 468/512 [00:47<00:04,  9.70it/s]\u001b[A\n",
            " 92% 469/512 [00:47<00:04,  9.66it/s]\u001b[A\n",
            " 92% 471/512 [00:48<00:04,  9.73it/s]\u001b[A\n",
            " 92% 472/512 [00:48<00:04,  9.76it/s]\u001b[A\n",
            " 93% 474/512 [00:48<00:03,  9.79it/s]\u001b[A\n",
            " 93% 475/512 [00:48<00:03,  9.76it/s]\u001b[A\n",
            " 93% 477/512 [00:48<00:03,  9.86it/s]\u001b[A\n",
            " 93% 478/512 [00:48<00:03,  9.84it/s]\u001b[A\n",
            " 94% 479/512 [00:48<00:03,  9.84it/s]\u001b[A\n",
            " 94% 481/512 [00:49<00:03,  9.84it/s]\u001b[A\n",
            " 94% 482/512 [00:49<00:03,  9.81it/s]\u001b[A\n",
            " 95% 484/512 [00:49<00:02,  9.89it/s]\u001b[A\n",
            " 95% 486/512 [00:49<00:02,  9.87it/s]\u001b[A\n",
            " 95% 487/512 [00:49<00:02,  9.89it/s]\u001b[A\n",
            " 95% 488/512 [00:49<00:02,  9.87it/s]\u001b[A\n",
            " 96% 490/512 [00:50<00:02,  9.89it/s]\u001b[A\n",
            " 96% 492/512 [00:50<00:02,  9.97it/s]\u001b[A\n",
            " 96% 493/512 [00:50<00:01,  9.95it/s]\u001b[A\n",
            " 96% 494/512 [00:50<00:01,  9.92it/s]\u001b[A\n",
            " 97% 495/512 [00:50<00:01,  9.88it/s]\u001b[A\n",
            " 97% 496/512 [00:50<00:01,  9.81it/s]\u001b[A\n",
            " 97% 497/512 [00:50<00:01,  9.75it/s]\u001b[A\n",
            " 97% 498/512 [00:50<00:01,  9.71it/s]\u001b[A\n",
            " 97% 499/512 [00:50<00:01,  9.71it/s]\u001b[A\n",
            " 98% 500/512 [00:51<00:01,  9.75it/s]\u001b[A\n",
            " 98% 501/512 [00:51<00:01,  9.78it/s]\u001b[A\n",
            " 98% 503/512 [00:51<00:00,  9.83it/s]\u001b[A\n",
            " 98% 504/512 [00:51<00:00,  9.86it/s]\u001b[A\n",
            " 99% 505/512 [00:51<00:00,  9.79it/s]\u001b[A\n",
            " 99% 506/512 [00:51<00:00,  9.77it/s]\u001b[A\n",
            " 99% 507/512 [00:51<00:00,  9.75it/s]\u001b[A\n",
            " 99% 508/512 [00:51<00:00,  9.69it/s]\u001b[A\n",
            " 99% 509/512 [00:52<00:00,  9.69it/s]\u001b[A\n",
            "100% 510/512 [00:52<00:00,  9.68it/s]\u001b[A\n",
            "100% 511/512 [00:52<00:00,  9.71it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.3163964748382568, 'eval_runtime': 52.4428, 'eval_samples_per_second': 9.763, 'eval_steps_per_second': 9.763, 'epoch': 4.23}\n",
            " 85% 200/235 [13:58<02:07,  3.65s/it]\n",
            "100% 512/512 [00:52<00:00,  9.68it/s]\u001b[A\n",
            "{'loss': 0.0224, 'learning_rate': 2.9629976105584266e-06, 'epoch': 4.44}\n",
            "{'loss': 0.0239, 'learning_rate': 1.0735204552657642e-06, 'epoch': 4.66}\n",
            "{'loss': 0.0237, 'learning_rate': 1.1966158316307208e-07, 'epoch': 4.87}\n",
            "100% 235/235 [16:06<00:00,  3.65s/it][INFO|trainer.py:1934] 2023-09-25 02:34:54,503 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 966.5754, 'train_samples_per_second': 1.955, 'train_steps_per_second': 0.243, 'train_loss': 0.11066707188778735, 'epoch': 4.97}\n",
            "100% 235/235 [16:06<00:00,  4.11s/it]\n",
            "[INFO|tokenization_utils_base.py:2210] 2023-09-25 02:34:55,761 >> tokenizer config file saved in /content/drive/MyDrive/Llama2_ch/output/sft_lora_model/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2217] 2023-09-25 02:34:55,766 >> Special tokens file saved in /content/drive/MyDrive/Llama2_ch/output/sft_lora_model/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       4.97\n",
            "  train_loss               =     0.1107\n",
            "  train_runtime            = 0:16:06.57\n",
            "  train_samples            =        378\n",
            "  train_samples_per_second =      1.955\n",
            "  train_steps_per_second   =      0.243\n",
            "09/25/2023 02:34:55 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:3081] 2023-09-25 02:34:55,798 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3083] 2023-09-25 02:34:55,798 >>   Num examples = 512\n",
            "[INFO|trainer.py:3086] 2023-09-25 02:34:55,798 >>   Batch size = 1\n",
            "100% 512/512 [00:52<00:00,  9.69it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       4.97\n",
            "  eval_loss               =      1.312\n",
            "  eval_runtime            = 0:00:52.93\n",
            "  eval_samples            =        512\n",
            "  eval_samples_per_second =      9.672\n",
            "  eval_steps_per_second   =      9.672\n",
            "  perplexity              =     3.7136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "33.1 gb 512 length"
      ],
      "metadata": {
        "id": "bobhaA1eXzNt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "1oFZpENleysf"
      ],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}